{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65378e2c-362d-44d6-880c-e363d90d925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a19ecf56-8bb4-45c4-b0ee-98719a77031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk_functions import bag_of_words, tokenize, stem\n",
    "from model import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a12e180-ef87-4d97-b8e9-99a7f210de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bdc1bfe-6108-448a-a67e-3e1c2fe78ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sarathdevsahadevan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9daca7-3711-4fdf-b1db-0d7e49935476",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "# loop through each sentence in our intents patterns\n",
    "for intent in intents['intents']:\n",
    "    tag = intent['tag']\n",
    "    # add to tag list\n",
    "    tags.append(tag)\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = tokenize(pattern)\n",
    "        # add to our words list\n",
    "        all_words.extend(w)\n",
    "        # add to xy pair\n",
    "        xy.append((w, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02632aff-e313-4f58-a357-996dc5f6a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem and lower each word\n",
    "ignore_words = ['?', '.', '!']\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "# remove duplicates and sort\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4baff5e8-2c6f-4334-a258-675c4119151d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 patterns\n",
      "105 tags: ['2fa, security', '360 account', 'Change online banking access code', 'account closure', 'account linking', 'account overdraft', 'account statement', 'activate overseas card usage, deactivate overseas card usage', 'add payee, delete payee, bill payment', 'add payee, delete payee, fund transfer', 'add payee, delete payee, overseas fund transfer', 'airport transfer', 'annual fee, annual fee waiver', 'apply, digital banking', 'atm dynamic currency conversion', 'atm, withdraw overseas', 'autowise, auto wise', 'autowise, insure, commercial vehicle', 'bill payment', 'billing organisations', 'branch locations', 'budgeting tools', 'business accounts', 'cancel fire insurance', 'cashier order', 'charitable donations', 'check balance', 'conversion rate, forex fee, conversion fee', 'corporate cards', 'credit card application', 'credit card rewards', 'credit limit increase', 'credit score inquiry', 'critical illness', 'customer service hours', 'debit card activation', 'dynamic currency conversion', 'electronic securities application', 'emergency assistance', 'fast', 'fee, ocbc cash cheques', 'fee, qr cash withdrawal', 'fee, srs', 'fee, srs account', 'financial education resources', 'financial planning services', 'foreign currency exchange', 'foreign exchange rates', 'fraudulent activity', 'giro, locked funds', 'goodbye', 'great life, endowment', 'greeting', 'insure, loss, ncd', 'interest calculation', 'interest rates', 'investment advice', 'investment options', 'investment risk assessment', 'ipo', 'loan application', 'loan refinancing', 'loan repayment', 'lost card', 'lost hardware token', 'mobile banking features', 'money, 360 account', 'mortgage application', 'non banking, financial institutions', 'notes denomination, qr cash withdrawal', 'old atm, access accounts', 'online banking security', 'online banking, public computer', 'online security tips', 'open account', 'open robo invest', 'overdraft facility', 'partial prepayment', 'pay through srs', 'payee', 'penalty, cancelling policy', 'phone banking', 'policy, add rider, remove rider', 'policy, benefits, guaranteed, non-guaranteed', 'policy, insurance, refund', 'policy, partial surrender', 'property loan', 'qr cash withdrawal', 'qr cash withdrawal limit', 'qr cash withdrawal, atm', 'qr cash withdrawal, cda, child development', 'qr cash withdrawal, foreign currency account', 'receive note, receive coin, cash cheque, atm', 'renew time deposit', 'reset password', 'rewards redemption', 'singpass passcode, login', 'spending limit', 'srs', 'student accounts', 'transaction history', 'transfer funds', 'transfer srs account', 'travel insurance', 'wealth management services']\n",
      "396 unique stemmed words: ['$', \"'s\", '(', ')', ',', '1', '1,000', '24/7', '2fa', '3', '360', ';', 'a', 'abl', 'about', 'access', 'account', 'accumul', 'activ', 'activation/', 'ad', 'add', 'addit', 'address', 'advic', 'advisor', 'after', 'against', 'airport', 'all', 'am', 'ambassador', 'amex', 'an', 'and', 'ani', 'annual', 'anoth', 'anyon', 'app', 'appli', 'applic', 'are', 'as', 'ask', 'assess', 'assist', 'associ', 'at', 'atm', 'automat', 'autowis', 'avail', 'balanc', 'bank', 'benefit', 'benefits/return', 'best', 'bill', 'block', 'board', 'both', 'bought', 'branch', 'budget', 'busi', 'by', 'bye', 'ca', 'calcul', 'can', 'cancel', 'card', 'case', 'cash', 'cashier', 'cda', 'chang', 'charg', 'charit', 'chariti', 'check', 'chequ', 'child', 'choos', 'claim', 'close', 'closur', 'code', 'coin', 'commerci', 'complimentari', 'comput', 'condit', 'consid', 'consolid', 'consult', 'contribut', 'conveni', 'convers', 'corpor', 'coverag', 'cpf', 'credit', 'critic', 'currenc', 'current', 'custom', 'day', 'dcc', 'deactiv', 'debit', 'debit/credit', 'delet', 'denomin', 'deposit', 'develop', 'diagnos', 'differ', 'digit', 'do', 'document', 'doe', 'donat', 'dure', 'dynam', 'e.g', 'easi', 'educ', 'electron', 'elig', 'els', 'emerg', 'enabl', 'endow', 'esa', 'evalu', 'exchang', 'exist', 'expens', 'explain', 'extern', 'facil', 'factor', 'fast', 'featur', 'fee', 'few', 'financi', 'find', 'fire', 'fix', 'for', 'foreign', 'forgot', 'form', 'fraud', 'fraudul', 'from', 'fund', 'get', 'giro', 'good', 'goodby', 'greatlif', 'guarante', 'hardwar', 'have', 'health', 'hello', 'help', 'hey', 'hi', 'histori', 'home', 'hotlin', 'hour', 'hous', 'how', 'i', 'if', 'ii', 'ill', 'impos', 'improv', 'in', 'includ', 'increas', 'incur', 'inform', 'institut', 'instruct', 'insur', 'interest', 'invest', 'ipo', 'is', 'issu', 'it', 'keep', 'knowledg', 'later', 'limit', 'link', 'literaci', 'loan', 'locat', 'lock', 'login', 'lose', 'loss', 'lost', 'make', 'manag', 'matur', 'me', 'measur', 'method', 'mine', 'minimum', 'mobil', 'money', 'monitor', 'month', 'monthli', 'more', 'mortgag', 'motor', 'multipl', 'my', \"n't\", 'ncd', 'nearest', 'need', 'new', 'nfi', 'non-bank', 'non-ocbc', 'not', 'note', 'number', 'obtain', 'ocbc', 'of', 'offer', 'old', 'on', 'one', 'onlin', 'open', 'oper', 'option', 'or', 'order', 'organ', 'organis', 'other', 'out', 'over', 'overdraft', 'oversea', 'partial', 'passcod', 'password', 'past', 'pay', 'paye', 'payment', 'penalti', 'perform', 'person', 'phone', 'pin', 'place', 'plan', 'point', 'polici', 'practic', 'pre-exist', 'prepay', 'prevail', 'privat', 'proce', 'procedur', 'process', 'product', 'program', 'promot', 'properti', 'protect', 'provid', 'public', 'purchas', 'qr', 'qualifi', 'quickest', 'rate', 'receiv', 'recent', 'recommend', 'recur', 'redeem', 'redempt', 'referenc', 'refin', 'refinanc', 'refund', 'regularli', 'rememb', 'remov', 'renew', 'repay', 'replac', 'report', 'request', 'requir', 'reset', 'resourc', 'retain', 'retir', 'reward', 'rider', 'risk', 'roboinvest', 's', 'safeguard', 'save', 'schedul', 'scheme', 'score', 'secur', 'see', 'servic', 'set', 'share', 'should', 'sibor', 'singapor', 'singpass', 'solut', 'some', 'someon', 'spend', 'sr', 'start', 'statement', 'step', 'still', 'stolen', 'student', 'supplementari', 'support', 'surrend', 'suspect', 'suspend', 'suspici', 'switch', 'tell', 'temporarili', 'term', 'than', 'the', 'their', 'there', 'these', 'through', 'time', 'to', 'token', 'toler', 'tool', 'track', 'transact', 'transfer', 'travel', 'type', 'up', 'usag', 'use', 'vehicl', 'via', 'view', 'visa', 'visa/mastercard', 'waiver', 'way', 'wealth', 'what', 'when', 'where', 'with', 'withdraw', 'without', 'work', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "print(len(xy), \"patterns\")\n",
    "print(len(tags), \"tags:\", tags)\n",
    "print(len(all_words), \"unique stemmed words:\", all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fbf55ea-3c45-40c3-87f7-17eccd1e7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    # X: bag of words for each pattern_sentence\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cb6a8b3-e566-4a2e-9d7c-476b16d13d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8915de79-7ab0-4119-b998-44c0cbbe0b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396 105\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 1000\n",
    "batch_size = 8\n",
    "learning_rate = 0.001\n",
    "input_size = len(X_train[0])\n",
    "hidden_size = 8\n",
    "output_size = len(tags)\n",
    "print(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc62ed01-afe3-4f60-8b2c-6f9594f4b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8eeb0997-dc12-4f91-8b62-a2ad9a5d1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c43f538-8f3f-4176-a7c6-3372a9bbad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb9fb863-02c1-43fd-ae4b-37a0b3fe6bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.1685\n",
      "Epoch [200/1000], Loss: 0.0030\n",
      "Epoch [300/1000], Loss: 0.0034\n",
      "Epoch [400/1000], Loss: 0.0002\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "final loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(words)\n",
    "        # if y would be one-hot, we must apply\n",
    "        # labels = torch.max(labels, 1)[1]\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "print(f'final loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ffd4b83-aac7-4d53-9672-776aba5b3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "\"model_state\": model.state_dict(),\n",
    "\"input_size\": input_size,\n",
    "\"hidden_size\": hidden_size,\n",
    "\"output_size\": output_size,\n",
    "\"all_words\": all_words,\n",
    "\"tags\": tags\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca8d9cf8-1513-4fba-bb78-31def4ad0e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "FILE = \"data.pth\"\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c27b5-9bab-41bb-a001-40f4096ae117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
